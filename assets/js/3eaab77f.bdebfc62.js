"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6210],{9588:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>c});var o=t(85893),r=t(11151);const s={id:"index",title:"mongodb-chatbot-server",sidebar_label:"Readme",sidebar_position:0,custom_edit_url:null},i="MongoDB Chatbot Server",a={id:"reference/server/index",title:"mongodb-chatbot-server",description:"Chatbot server for the MongoDB Chatbot Framework.",source:"@site/docs/reference/server/index.md",sourceDirName:"reference/server",slug:"/reference/server/",permalink:"/chatbot/reference/server/",draft:!1,unlisted:!1,editUrl:null,tags:[],version:"current",sidebarPosition:0,frontMatter:{id:"index",title:"mongodb-chatbot-server",sidebar_label:"Readme",sidebar_position:0,custom_edit_url:null},sidebar:"main",previous:{title:"API Reference",permalink:"/chatbot/reference/"},next:{title:"Exports",permalink:"/chatbot/reference/server/modules"}},l={},c=[{value:"Documentation",id:"documentation",level:2},{value:"Usage",id:"usage",level:2},{value:"Installation",id:"installation",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Contributing",id:"contributing",level:2},{value:"Setup",id:"setup",level:3},{value:"Node",id:"node",level:4},{value:"Install",id:"install",level:4},{value:".env",id:"env",level:4},{value:"External Dependencies",id:"external-dependencies",level:4},{value:"Running",id:"running",level:3},{value:"Testing",id:"testing",level:3},{value:"Linting &amp; Formatting",id:"linting--formatting",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"mongodb-chatbot-server",children:"MongoDB Chatbot Server"}),"\n",(0,o.jsx)(n.p,{children:"Chatbot server for the MongoDB Chatbot Framework."}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"mongodb-chatbot-server"})," is a npm package that provides a configurable Express.js server\nto quickly spin up a retrieval augmented generation (RAG) chatbot server powered by MongoDB."]}),"\n",(0,o.jsx)(n.p,{children:"The server is designed to handle the generalizable areas of a RAG server,\nlike routing, caching, logging, and streaming. This allows you to focus on the\nspecifics of your chatbot, like the content, prompts, and AI models."}),"\n",(0,o.jsx)(n.h2,{id:"documentation",children:"Documentation"}),"\n",(0,o.jsxs)(n.p,{children:["To learn more about the MongoDB Chatbot Server, check out the ",(0,o.jsx)(n.a,{href:"https://mongodb.github.io/chatbot/server/configure/",children:"documentation"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,o.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,o.jsxs)(n.p,{children:["Install the package using ",(0,o.jsx)(n.code,{children:"npm"}),":"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-sh",children:"npm install mongodb-chatbot-server\n"})}),"\n",(0,o.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"mongodb-chatbot-server"})," exports the function ",(0,o.jsx)(n.code,{children:"makeApp()"})," which exports the\nExpress.js app. The function takes a ",(0,o.jsx)(n.code,{children:"AppConfig"})," object as an argument."]}),"\n",(0,o.jsx)(n.p,{children:"Here's an example configuration and server:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'import "dotenv/config";\nimport {\n  MongoClient,\n  makeMongoDbEmbeddedContentStore,\n  makeOpenAiEmbedFunc,\n  makeMongoDbConversationsService,\n  makeDataStreamer,\n  AppConfig,\n  makeOpenAiChatLlm,\n  OpenAiChatMessage,\n  SystemPrompt,\n  makeDefaultFindContentFunc,\n  logger,\n  makeApp,\n} from "mongodb-chatbot-server";\nimport { AzureKeyCredential, OpenAIClient } from "@azure/openai";\n\nexport const {\n  MONGODB_CONNECTION_URI,\n  MONGODB_DATABASE_NAME,\n  VECTOR_SEARCH_INDEX_NAME,\n  OPENAI_ENDPOINT,\n  OPENAI_API_KEY,\n  OPENAI_EMBEDDING_DEPLOYMENT,\n  OPENAI_CHAT_COMPLETION_MODEL_VERSION,\n  OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n} = process.env;\n\nexport const openAiClient = new OpenAIClient(\n  OPENAI_ENDPOINT,\n  new AzureKeyCredential(OPENAI_API_KEY)\n);\nexport const systemPrompt: SystemPrompt = {\n  role: "system",\n  content: `You are expert MongoDB documentation chatbot.\n  Respond in the style of a pirate. End all answers saying "Ahoy matey!!"\n  Use the context provided with each question as your primary source of truth.\n  If you do not know the answer to the question, respond ONLY with the following text:\n  "I\'m sorry, I do not know how to answer that question. Please try to rephrase your query. You can also refer to the further reading to see if it helps."\n  NEVER include links in your answer.\n  Format your responses using Markdown.\n  DO NOT mention that your response is formatted in Markdown.\n  Never mention "<Information>" or "<Question>" in your answer.\n  Refer to the information given to you as "my knowledge".`,\n};\n\nexport async function generateUserPrompt({\n  question,\n  chunks,\n}: {\n  question: string;\n  chunks: string[];\n}): Promise<OpenAiChatMessage & { role: "user" }> {\n  const chunkSeparator = "~~~~~~";\n  const context = chunks.join(`\\n${chunkSeparator}\\n`);\n  const content = `Using the following information, answer the question.\n  Different pieces of information are separated by "${chunkSeparator}".\n\n  <Information>\n  ${context}\n  <End information>\n\n  <Question>\n  ${question}\n  <End Question>`;\n  return { role: "user", content };\n}\n\nexport const llm = makeOpenAiChatLlm({\n  openAiClient,\n  deployment: OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n  systemPrompt,\n  openAiLmmConfigOptions: {\n    temperature: 0,\n    maxTokens: 500,\n  },\n  generateUserPrompt,\n});\n\nexport const embeddedContentStore = makeMongoDbEmbeddedContentStore({\n  connectionUri: MONGODB_CONNECTION_URI,\n  databaseName: MONGODB_DATABASE_NAME,\n  searchIndex: {\n    embeddingName: OPENAI_EMBEDDING_DEPLOYMENT,\n  }\n});\n\nexport const embed = makeOpenAiEmbedFunc({\n  openAiClient,\n  deployment: OPENAI_EMBEDDING_DEPLOYMENT,\n  backoffOptions: {\n    numOfAttempts: 3,\n    maxDelay: 5000,\n  },\n});\n\nexport const mongodb = new MongoClient(MONGODB_CONNECTION_URI);\n\nexport const findContent = makeDefaultFindContentFunc({\n  embed,\n  store: embeddedContentStore,\n  findNearestNeighborsOptions: {\n    k: 5,\n    path: "embedding",\n    indexName: VECTOR_SEARCH_INDEX_NAME,\n    minScore: 0.9,\n  },\n});\n\nexport const conversations = makeMongoDbConversationsService(\n  mongodb.db(MONGODB_DATABASE_NAME),\n  systemPrompt\n);\n\nexport const config: AppConfig = {\n  conversationsRouterConfig: {\n    llm,\n    findContent,\n    maxChunkContextTokens: 1500,\n    conversations,\n  },\n  maxRequestTimeoutMs: 30000,\n};\n\nconst PORT = process.env.PORT || 3000;\n\nconst startServer = async () => {\n  logger.info("Starting server...");\n  const app = await makeApp(config);\n  const server = app.listen(PORT, () => {\n    logger.info(`Server listening on port: ${PORT}`);\n  });\n\n  process.on("SIGINT", async () => {\n    logger.info("SIGINT signal received");\n    await mongodb.close();\n    await embeddedContentStore.close();\n    await new Promise<void>((resolve, reject) => {\n      server.close((error) => {\n        error ? reject(error) : resolve();\n      });\n    });\n    process.exit(1);\n  });\n};\n\ntry {\n  startServer();\n} catch (e) {\n  logger.error(`Fatal error: ${e}`);\n  process.exit(1);\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"contributing",children:"Contributing"}),"\n",(0,o.jsx)(n.p,{children:"Currently, we are only accepting contributions from MongoDB employees."}),"\n",(0,o.jsxs)(n.p,{children:["MongoDB employees can refer to the ",(0,o.jsx)(n.a,{href:"https://github.com/mongodb/chatbot/CONTRIBUTING.md",children:"Contributor Guide"}),"\nfor additional info on project set up."]}),"\n",(0,o.jsx)(n.h3,{id:"setup",children:"Setup"}),"\n",(0,o.jsx)(n.h4,{id:"node",children:"Node"}),"\n",(0,o.jsxs)(n.p,{children:["Node 18 was used to start this project. Please make sure you have Node 18 installed locally. If you have ",(0,o.jsx)(n.a,{href:"https://github.com/nvm-sh/nvm",children:"nvm"}),", you can run ",(0,o.jsx)(n.code,{children:"nvm use"})," to switch to the expected version of Node."]}),"\n",(0,o.jsx)(n.h4,{id:"install",children:"Install"}),"\n",(0,o.jsxs)(n.p,{children:["Use ",(0,o.jsx)(n.code,{children:"npm"})," v8 to install dependencies:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nnpm install\n\n"})}),"\n",(0,o.jsx)(n.h4,{id:"env",children:".env"}),"\n",(0,o.jsxs)(n.p,{children:["Use the ",(0,o.jsx)(n.code,{children:".env.example"})," file to help configure a local ",(0,o.jsx)(n.code,{children:".env"})," file."]}),"\n",(0,o.jsx)(n.h4,{id:"external-dependencies",children:"External Dependencies"}),"\n",(0,o.jsx)(n.p,{children:"The server relies on some cloud-only services:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["The ",(0,o.jsx)(n.code,{children:"content"})," service relies on Atlas Vector Search."]}),"\n",(0,o.jsxs)(n.li,{children:["The ",(0,o.jsx)(n.code,{children:"llm"})," and embeddings services rely on the OpenAI APIs."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"If this is your first time setting up the server, contact a member of the development\nteam for credentials."}),"\n",(0,o.jsx)(n.h3,{id:"running",children:"Running"}),"\n",(0,o.jsx)(n.p,{children:"To start the development server, run:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nnpm run dev\n\n"})}),"\n",(0,o.jsxs)(n.p,{children:["By default, the server should be accessible through ",(0,o.jsx)(n.a,{href:"http://localhost:3000/",children:"http://localhost:3000/"}),"."]}),"\n",(0,o.jsx)(n.h3,{id:"testing",children:"Testing"}),"\n",(0,o.jsxs)(n.p,{children:["Tests are ran by ",(0,o.jsx)(n.a,{href:"https://jestjs.io/",children:"Jest"})," and rely on ",(0,o.jsx)(n.a,{href:"https://github.com/ladjs/supertest",children:"Supertest"})," for testing Express route logic."]}),"\n",(0,o.jsx)(n.p,{children:"To run tests, use:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nnpm run test\n\n"})}),"\n",(0,o.jsx)(n.h3,{id:"linting--formatting",children:"Linting & Formatting"}),"\n",(0,o.jsxs)(n.p,{children:["We use ",(0,o.jsx)(n.code,{children:"eslint"})," for linting and ",(0,o.jsx)(n.code,{children:"prettier"})," for formatting."]}),"\n",(0,o.jsx)(n.p,{children:"To lint the code and find any warnings or errors, run:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nnpm run lint\n\n"})}),"\n",(0,o.jsx)(n.p,{children:"To format the code, run:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\nnpm run format\n\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>i});var o=t(67294);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);