"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7574],{2043:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>c});var t=s(5893),o=s(1151);const r={},a="Responses API",i={id:"server/responses-api",title:"Responses API",description:"The MongoDB Knowledge Service Responses API lets you get LLM-generated answers to MongoDB-related topics.",source:"@site/docs/server/responses-api.md",sourceDirName:"server",slug:"/server/responses-api",permalink:"/chatbot/server/responses-api",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb/chatbot/tree/main/docs/docs/server/responses-api.md",tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"Home",permalink:"/chatbot/"},next:{title:"Chatbot UI",permalink:"/chatbot/ui"}},l={},c=[{value:"API Specification",id:"api-specification",level:2},{value:"Call the Responses API",id:"call-the-responses-api",level:2},{value:"OpenAI Client",id:"openai-client",level:3},{value:"Vercel AI SDK",id:"vercel-ai-sdk",level:3},{value:"<code>curl</code> Request",id:"curl-request",level:3},{value:"Retrieval-Augmented Generation",id:"retrieval-augmented-generation",level:2},{value:"Set Custom Instructions",id:"set-custom-instructions",level:2},{value:"Use Custom Tools",id:"use-custom-tools",level:2},{value:"Force Tool Choice",id:"force-tool-choice",level:3},{value:"Combine Custom Tools with Custom Instructions",id:"combine-custom-tools-with-custom-instructions",level:3},{value:"Conversation Management",id:"conversation-management",level:2},{value:"Message Storage",id:"message-storage",level:3},{value:"Stateful Conversations",id:"stateful-conversations",level:3},{value:"Stateless Conversations",id:"stateless-conversations",level:3},{value:"Guardrails",id:"guardrails",level:2},{value:"Tracing and Storage",id:"tracing-and-storage",level:2},{value:"Collect User Feedback",id:"collect-user-feedback",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"responses-api",children:"Responses API"}),"\n",(0,t.jsx)(n.p,{children:"The MongoDB Knowledge Service Responses API lets you get LLM-generated answers to MongoDB-related topics."}),"\n",(0,t.jsx)(n.p,{children:"The Responses API includes the following features:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Multi-Client Support:"})," The interface of the MongoDB Knowledge Service Responses API is a subset of the official ",(0,t.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/responses",children:"OpenAI Responses API"}),". This means you can call the MongoDB Responses API through any client that supports the OpenAI Responses API."]}),"\n",(0,t.jsxs)(n.p,{children:["To learn more, refer to the ",(0,t.jsx)(n.a,{href:"#call-the-responses-api",children:"Call the Responses API"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Retrieval-Augmented Generation:"})," By default, the API performs retrieval-augmented generation under the hood to generate accurate and up-to-date responses about MongoDB products."]}),"\n",(0,t.jsxs)(n.p,{children:["To learn more, refer to the ",(0,t.jsx)(n.a,{href:"#retrieval-augmented-generation",children:"Retrieval-Augmented Generation"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Personality:"}),' The AI API has the personality of a helpful MongoDB assistant. You cannot change this core personality. You can augment the personality via custom instructions. (E.g. "You are a technical services engineer at MongoDB. Use that as context to inform your response.")']}),"\n",(0,t.jsxs)(n.p,{children:["To learn more about augmenting the personality, refer to ",(0,t.jsx)(n.a,{href:"#set-custom-instructions",children:"Set Custom Instructions"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Custom Tools:"})," You can add custom function tools to the Responses API, allowing you to extend the functionality of the Responses API to support additional use cases."]}),"\n",(0,t.jsxs)(n.p,{children:["For more information, refer to the ",(0,t.jsx)(n.a,{href:"#use-custom-tools",children:"Use Custom Tools"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Stateful and Stateless:"})," The API supports stateful and stateless conversation management. If you're using stateful conversation management, the conversation history is managed on the server. To use stateless conversation management, define the conversation context in each request from the client."]}),"\n",(0,t.jsxs)(n.p,{children:["For more information, refer to the ",(0,t.jsx)(n.a,{href:"#conversation-management",children:"Conversation Management"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Guardrails:"})," The API features guardrails that helps ensure the input and output are appropriate for a MongoDB assistant. This protects the API from generating irrelevant or malicious responses."]}),"\n",(0,t.jsxs)(n.p,{children:["For more information, refer to the ",(0,t.jsx)(n.a,{href:"#guardrails",children:"Guardrails"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Tracing & Storage:"})," All messages to the chatbot can be traced and stored or not depending on how you configure your request."]}),"\n",(0,t.jsxs)(n.p,{children:["For more information, refer to the ",(0,t.jsx)(n.a,{href:"#tracing-and-storage",children:"Tracing and Storage"})," section."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Collect User Feedback:"})," You can rate and comment all messages from the Responses API. This is useful for tracking user feedback and API performance for your use case."]}),"\n",(0,t.jsxs)(n.p,{children:["For more information, refer to the ",(0,t.jsx)(n.a,{href:"#collect-user-feedback",children:"Collect User Feedback"})," section."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"api-specification",children:"API Specification"}),"\n",(0,t.jsxs)(n.p,{children:["For a complete reference on the MongoDB Responses API, refer to the ",(0,t.jsx)(n.a,{href:"./openapi#tag/Responses",children:"OpenAPI specification"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"call-the-responses-api",children:"Call the Responses API"}),"\n",(0,t.jsx)(n.p,{children:"As the MongoDB Knowledge Service Responses API uses the same interface as the OpenAI responses API, all clients that support the official OpenAI Responses API should also work for this API."}),"\n",(0,t.jsx)(n.p,{children:"The Education AI team actively develops against the JavaScript Vercel AI SDK and the OpenAI client library."}),"\n",(0,t.jsxs)(n.p,{children:["Currently the Responses API only supports streaming using SSE. For all requests, you ",(0,t.jsx)(n.strong,{children:"must"})," set ",(0,t.jsx)(n.code,{children:"stream: true"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["If you are new to working with LLM APIs, you can search the web for examples of using the official OpenAI Responses API. As our API uses a subset of the same specification, these examples should be broadly applicable as well. The ",(0,t.jsx)(n.a,{href:"https://github.com/openai/openai-responses-starter-app",children:"OpenAI Responses starter app"})," is a good complete application reference."]}),"\n",(0,t.jsx)(n.h3,{id:"openai-client",children:"OpenAI Client"}),"\n",(0,t.jsxs)(n.p,{children:["Example usage with OpenAI client ",(0,t.jsx)(n.code,{children:"openai"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst response = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n});\n\nfor await (const event of response) {\n  console.log(event);\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"vercel-ai-sdk",children:"Vercel AI SDK"}),"\n",(0,t.jsxs)(n.p,{children:["Example usage with ",(0,t.jsx)(n.a,{href:"https://ai-sdk.dev/docs/introduction",children:"Vercel AI SDK"})," ",(0,t.jsx)(n.code,{children:"@ai-sdk/openai"})," and ",(0,t.jsx)(n.code,{children:"ai"})," libraries:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'// NOTE: The Responses API currently only support streaming responses via methods like `streamText`. Methods that do not use streaming like `generateText` will not work.\nimport { streamText } from "ai";\n// NOTE: we are using the AI SDK v5 with LanguageModelV2\nimport { createOpenAI } from "@ai-sdk/openai";\n\nconst model = createOpenAI({\n  baseURL: origin + API_PREFIX,\n  apiKey: TEST_OPENAI_API_KEY,\n}).responses("mongodb-chat-latest");\n\nconst result = await streamText({\n  model,\n  prompt: "What is MongoDB?",\n});\n\nfor await (const chunk of result.toUIMessageStream()) {\n  console.log(chunk);\n}\n'})}),"\n",(0,t.jsxs)(n.h3,{id:"curl-request",children:[(0,t.jsx)(n.code,{children:"curl"})," Request"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:'curl -v -X POST POST \'https://knowledge.mongodb.com/api/v1/responses\' \\\n  -H \'Content-Type: application/json\' \\\n  -H \'ORIGIN: mongodb.com\' \\\n  -d \'{\n    "model": "mongodb-chat-latest",\n    "stream": true,\n    "input": "How do I create an index in MongoDB?",\n  }\'\n'})}),"\n",(0,t.jsx)(n.h2,{id:"retrieval-augmented-generation",children:"Retrieval-Augmented Generation"}),"\n",(0,t.jsx)(n.p,{children:"By default, the API performs retrieval-augmented generation under the hood\nto generate accurate and up-to-date responses about MongoDB products.\nRetrieval is managed by internal search tools.\nThese internal search tools cannot be removed from the API."}),"\n",(0,t.jsxs)(n.p,{children:["The API returns references to any sources used to generate the response in the ",(0,t.jsx)(n.code,{children:'"response.output_text.annotation.added"'})," stream event. These stream events are only included if an internal search tool was called."]}),"\n",(0,t.jsxs)(n.p,{children:["If you provide custom tools to the API via the ",(0,t.jsx)(n.code,{children:"tools"})," parameter,\nthe API will choose to use the tool or the retrieval tool based on the ",(0,t.jsx)(n.code,{children:"tool_choice"})," parameter.\nDefault behavior is to allow the model to choose the tool to use (",(0,t.jsx)(n.code,{children:'tool_choice: "auto"'}),")."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'const stream = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n  // Uses RAG under the hood by default\n});\n\nfor await (const event of stream) {\n    switch(event.type) {\n        // You stuff with the reference, like populate the UI.\n        case "response.output_text.annotation.added":\n            console.log(event);\n            break;\n        // ...other cases\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"set-custom-instructions",children:"Set Custom Instructions"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst response = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n  // Custom instructions\n  instructions: "You are located on the MongoDB Atlas cloud platform. Use that as context to inform your response."\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"use-custom-tools",children:"Use Custom Tools"}),"\n",(0,t.jsx)(n.p,{children:"You can add custom tools to the Responses API to make it produce structured output or agentically interact with services."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\n//Custom tool definition\nconst tools =  [{\n    type: "function",\n    name: "test-tool",\n    description: "A tool for testing.",\n    parameters: {\n        type: "object",\n        properties: {\n            query: { type: "string" },\n        },\n        required: ["query"],\n    },\n}];\n\nconst stream = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n  // Pass tools array\n  tools,\n  // By default, the Responses API uses `tool_choice: "auto"`.\n  // With this parameter, the model decides whether to call a tool\n  // and which tool to call.\n  // The model may chose to call one of the internal search tools\n  // when using `tool_choice: "auto"`.\n  // tool_choice: "auto"\n});\n'})}),"\n",(0,t.jsx)(n.h3,{id:"force-tool-choice",children:"Force Tool Choice"}),"\n",(0,t.jsxs)(n.p,{children:["You can force the Responses API to use a custom tool with the ",(0,t.jsx)(n.code,{children:"tool_choice"})," parameter:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst tools =  [{\n  type: "function",\n  name: "test-tool",\n  description: "A tool for testing.",\n  parameters: {\n    type: "object",\n    properties: {\n      query: { type: "string" },\n    },\n    required: ["query"],\n  },\n}];\n\nconst stream = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n  tools,\n  // Force calling the tool\n  tool_choice: {\n    type: "function",\n    name: tools[0].name,\n  }\n});\n'})}),"\n",(0,t.jsx)(n.h3,{id:"combine-custom-tools-with-custom-instructions",children:"Combine Custom Tools with Custom Instructions"}),"\n",(0,t.jsxs)(n.p,{children:["You can use custom instructions to give the model additional context about how to use custom tools. To do this, use both the ",(0,t.jsx)(n.code,{children:"instructions"})," and ",(0,t.jsx)(n.code,{children:"tools"})," parameters on the request to the Responses API:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst tools =  [{\n  type: "function",\n  name: "mongosh-query",\n  description: "Write a Mongosh query",\n  parameters: {\n    type: "object",\n    properties: {\n      mongosh_query: { type: "string" },\n    },\n    required: ["query"],\n  },\n}];\n\nconst stream = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "how to aggregate data in movies collection?",\n    },\n  ],\n  tools,\n  // Instructions guiding tool usage\n  instructions: `## ${tools[0].name} usage\n  \nIf you use the \'${tools[0].name}\' tool,\nalways format the output as follows:\ndb.<collection-name>.<operation>(...args)\n\n### Cursor-Returning Operations\n\nFor cursor-returning operations like .find() and .aggregate(),\npostfix the query with the appropriate method\nto convert it to the data from the database,\nlike .toArray() or .explain().\nEx: db.<collection-name>.<find|aggregate>(...args).toArray()\n\n## Limiting Queries\n\nUnless explicitly told otherwise by the user, limit queries to at most 10 documents.\nEx:\n- { $limit: 10} for .aggregate()\n- .limit(10) for .find()\n\n...more instructions...`\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"conversation-management",children:"Conversation Management"}),"\n",(0,t.jsx)(n.p,{children:"The Responses API supports both stateful and stateless conversation management."}),"\n",(0,t.jsx)(n.h3,{id:"message-storage",children:"Message Storage"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"store"})," parameter determines how the server persists conversations, and whether or not you can use stateful conversations.\nBy default if store ",(0,t.jsx)(n.code,{children:"store: undefined"}),", the server stores conversations.\nYou can also explicitly set ",(0,t.jsx)(n.code,{children:"store: true"})," for the same behavior."]}),"\n",(0,t.jsxs)(n.p,{children:["If you set ",(0,t.jsx)(n.code,{children:"store: false"}),", the database does not persist conversation messages, though it does persist non-sensitive metadata about the messages."]}),"\n",(0,t.jsxs)(n.p,{children:["Only set ",(0,t.jsx)(n.code,{children:"store: false"})," if your use case requires that the server does not persist conversation messages. For example, you should not store conversations if they contain sensitive customer data."]}),"\n",(0,t.jsxs)(n.p,{children:["If your use case requires back-and-forth AND ",(0,t.jsx)(n.code,{children:"store: true | undefined"}),", prefer using stateful conversations, as documented in the following section."]}),"\n",(0,t.jsx)(n.h3,{id:"stateful-conversations",children:"Stateful Conversations"}),"\n",(0,t.jsxs)(n.p,{children:["In stateful conversations, the server manages conversation history. You reference previous messages using the ",(0,t.jsx)(n.code,{children:"previous_response_id"})," parameter, and the server maintains the context automatically."]}),"\n",(0,t.jsxs)(n.p,{children:["By setting ",(0,t.jsx)(n.code,{children:"previous_response_id"}),", all messages in conversation are stored together in the database. This makes conversations easier to analyze."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Requirements for stateful conversations:"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Must set ",(0,t.jsx)(n.code,{children:"store: true | undefined"})]}),"\n",(0,t.jsxs)(n.li,{children:["Must use the same ",(0,t.jsx)(n.code,{children:"user"})," ID for all requests in the conversation"]}),"\n",(0,t.jsx)(n.li,{children:"Maximum of 50 user messages per conversation"}),"\n",(0,t.jsx)(n.li,{children:"Each follow-up must reference the immediately previous response ID"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"If any of these requirements are violated, the server responds with an error."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\nconst userId = "user123";\n\n// First message in conversation\nconst firstResponse = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: "What is MongoDB?",\n  store: true, // Required for stateful conversations\n  user: userId\n});\n\nlet previousResponseId: string;\nlet conversationId: string;\n\nfor await (const event of firstResponse) {\n  switch (event.type) {\n    case "response.completed":\n      previousResponseId = event.response.id;\n      conversationId = event.response.metadata.conversation_id;\n      break;\n  }\n}\n\n// Follow-up message using previous_response_id\nconst followUpResponse = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: "How do I install it?",\n  previous_response_id: previousResponseId, // Links to previous conversation\n  store: true,\n  user: userId // Must be the same user ID\n});\n'})}),"\n",(0,t.jsx)(n.h3,{id:"stateless-conversations",children:"Stateless Conversations"}),"\n",(0,t.jsx)(n.p,{children:"In stateless conversations, you provide the entire conversation context in each request."}),"\n",(0,t.jsxs)(n.p,{children:["You can use stateless conversations for any storage setting,  ",(0,t.jsx)(n.code,{children:"store: true | false | undefined"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["If you set ",(0,t.jsx)(n.code,{children:"store: false"}),", you ",(0,t.jsx)(n.strong,{children:"must"})," use a stateless conversation because the server doesn't maintain conversation history."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst firstMessage = {\n  type: "message",\n  role: "user",\n  content: "What is MongoDB?"\n}\n// First message\nconst firstResponse = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [firstMessage],\n  store: false // Does not store conversation on server\n});\n\n// Get first response text to include in subsequent requests\nlet firstResponseOutputText = "";\nfor await (const event of firstResponse) {\n  switch (event.type) {\n    case "response.completed":\n      firstResponseOutputText = event.response.output_text;\n      break;\n    default:\n      continue;\n  }\n}\n\n// Follow-up message with full conversation history\nconst followUpResponse = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    // Passing first message again because stateless conversation\n    firstMessage,\n    {\n      type: "message",\n      role: "assistant",\n      content: firstResponseOutputText,\n    },\n    {\n      type: "message",\n      role: "user",\n      content: "How do I install it?"\n    }\n  ],\n  store: false\n});\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Benefits of stateless conversations:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Works with ",(0,t.jsx)(n.code,{children:"store: false"})," for privacy"]}),"\n",(0,t.jsx)(n.li,{children:"No user ID consistency requirements"}),"\n",(0,t.jsx)(n.li,{children:"Full control over conversation context"}),"\n",(0,t.jsx)(n.li,{children:"No 50 message limit (though total content must be \u2264250,000 characters)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Considerations:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"More bandwidth usage (sending full context each time)"}),"\n",(0,t.jsx)(n.li,{children:"Client responsible for managing conversation history"}),"\n",(0,t.jsx)(n.li,{children:"Must manually track and include all relevant context"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"guardrails",children:"Guardrails"}),"\n",(0,t.jsx)(n.p,{children:"The API features a few levels of guardrails to prevent use for irrelevant or malicious purposes. For security reasons, you cannot configure or turn the guardrails off."}),"\n",(0,t.jsx)(n.p,{children:"Guardrails:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Input guardrail"}),": Before generating a response, the server runs a separate LLM call to check that all natural language input is relevant and not malicious. The input guardrail checks the ",(0,t.jsx)(n.code,{children:"input"})," messages, ",(0,t.jsx)(n.code,{children:"instructions"})," system prompt, and custom ",(0,t.jsx)(n.code,{children:"tools"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"System prompt"}),": The system prompt used with all responses specifies that the model output should not speak negatively toward MongoDB and represent the company well."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LLM content filter"}),": The LLM API used by the Responses API has guardrails to make sure that the model does not response to inappropriate or offensive content."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"tracing-and-storage",children:"Tracing and Storage"}),"\n",(0,t.jsxs)(n.p,{children:["All messages to the Responses API are traced and stored in MongoDB if ",(0,t.jsx)(n.code,{children:"store: true | undefined"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["If ",(0,t.jsx)(n.code,{children:"store: false"}),", the Responses API only stores basic metadata."]}),"\n",(0,t.jsxs)(n.p,{children:["For access to chatbot data, ",(0,t.jsx)(n.a,{href:"/chatbot/contact",children:"contact the Education AI team"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"All data retention is in line with MongoDB data retention policies."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import { OpenAI } from "openai";\n\nconst openai = new OpenAI({ baseURL: "https://knowledge.mongodb.com/api/v1" });\n\nconst stream = await openai.responses.create({\n  model: "mongodb-chat-latest",\n  stream: true,\n  input: [\n    {\n      role: "user",\n      content: "So what\'s MongoDB anyways??",\n    },\n  ],\n  // Store conversation\n  store: true\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"collect-user-feedback",children:"Collect User Feedback"}),"\n",(0,t.jsx)(n.p,{children:"You can collect user feedback in the form of message ratings and comments on all generations from the Responses API. The Knowledge Service has separate endpoints for rating and commenting messages:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsxs)(n.a,{href:"./openapi#tag/Conversations/operation/rateMessage",children:[(0,t.jsx)(n.code,{children:"rateMessage"})," endpoint"]})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsxs)(n.a,{href:"/openapi#tag/Conversations/operation/commentMessage",children:[(0,t.jsx)(n.code,{children:"commentMessage"})," endpoint"]})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Usage example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"import { OpenAI } from \"openai\";\n\nconst knowledgeServiceBaseUrl = \"https://knowledge.mongodb.com/api/v1\";\n\nconst openai = new OpenAI({ baseURL: knowledgeServiceBaseUrl });\n\nconst stream = await openai.responses.create({\n  model: \"mongodb-chat-latest\",\n  stream: true,\n  input: [\n    {\n      role: \"user\",\n      content: \"So what's MongoDB anyways??\",\n    },\n  ],\n});\n\nlet messageId: string;\nlet conversationId: string;\n\nfor await (const event of stream) {\n  switch(event.type) {\n    case \"response.completed\":\n      // Extract the message ID and conversation ID for rating/commenting\n      messageId = event.response.id;\n      conversationId = event.response.metadata.conversation_id;\n      break;\n    // ...other event handling\n  }\n}\n\n// Rate the message (thumbs up/down)\nconst rateResponse = await fetch(`${knowledgeServiceBaseUrl}/conversations/${conversationId}/messages/${messageId}/rating`, {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'ORIGIN': 'your-domain.com'\n  },\n  body: JSON.stringify({\n    rating: true // true for thumbs up, false for thumbs down\n  })\n});\n\n// Add a comment to the message (requires the message to be rated first)\nconst commentResponse = await fetch(`${knowledgeServiceBaseUrl}/conversations/${conversationId}/messages/${messageId}/comment`, {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'ORIGIN': 'your-domain.com'\n  },\n  body: JSON.stringify({\n    comment: \"This response was very helpful for understanding MongoDB Atlas setup.\"\n  })\n});\n"})})]})}function h(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);