"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7945],{94583:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>l,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var o=t(85893),a=t(11151);const i={},s="Optimize Ingestion",r={id:"ingest/optimize",title:"Optimize Ingestion",description:"You can optimize your data ingestion process for your application.",source:"@site/docs/ingest/optimize.md",sourceDirName:"ingest",slug:"/ingest/optimize",permalink:"/chatbot/ingest/optimize",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb/chatbot/tree/main/docs/docs/ingest/optimize.md",tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"Data Sources",permalink:"/chatbot/ingest/data-sources"},next:{title:"Configure the Chatbot Server",permalink:"/chatbot/server/configure"}},d={},c=[{value:"Standardize Data Formats",id:"standardize-data-formats",level:2},{value:"Text",id:"text",level:3},{value:"Structured Data",id:"structured-data",level:3},{value:"Clean up Text as You Ingest",id:"clean-up-text-as-you-ingest",level:2},{value:"Refine the Chunking Strategy",id:"refine-the-chunking-strategy",level:2},{value:"Add Metadata to Chunks",id:"add-metadata-to-chunks",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"optimize-ingestion",children:"Optimize Ingestion"}),"\n",(0,o.jsx)(n.p,{children:"You can optimize your data ingestion process for your application."}),"\n",(0,o.jsx)(n.p,{children:"This page contains some information on optimizing ingestion\nbased on our experience building RAG applications and emerging best practices."}),"\n",(0,o.jsx)(n.h2,{id:"standardize-data-formats",children:"Standardize Data Formats"}),"\n",(0,o.jsx)(n.p,{children:"We recommend that you standardize the data formats for the content that you ingest\ninto your RAG application. This is advantageous for the following reasons:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"It's easier for the LLM to reason about the content when generating responses"}),"\n",(0,o.jsx)(n.li,{children:"You can share helper methods across data sources"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"text",children:"Text"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://www.markdownguide.org/",children:"Markdown"})," works well as the standard format for most text-based content. LLMs can reason with Markdown,\nand even respond in Markdown. (This is actually how ChatGPT creates rich text).\nThere are lots of tools in the JavaScript ecosystem for working with Markdown as well."]}),"\n",(0,o.jsx)(n.p,{children:"HTML is generally a suboptimal format for RAG. While LLMs can reason with HTML,\nit has a much higher token density for the same content as compared to Markdown\nfor most tokenization algorithms. This is because of all those HTML tags."}),"\n",(0,o.jsx)(n.p,{children:"And if you need to include some HTML semantic meaning in your content that\nMarkdown doesn't support, you can use that HTML in your Markdown. This works because:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"LLMs aren't sticklers for language syntax, generally speaking."}),"\n",(0,o.jsxs)(n.li,{children:["In some Markdown dialects, like ",(0,o.jsx)(n.a,{href:"https://github.github.com/gfm/",children:"Github Flavored Markdown"}),", you can include HTML in Markdown. This further reduces potential LLM confusion and means that\nthere exist non-AI libraries and tools to work with hybrid Markdown/HTML content programmatically."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"structured-data",children:"Structured Data"}),"\n",(0,o.jsxs)(n.p,{children:["If you are embedding structured data, you can use ",(0,o.jsx)(n.a,{href:"https://yaml.org/",children:"YAML"}),"\nor ",(0,o.jsx)(n.a,{href:"https://www.json.org/json-en.html",children:"JSON"}),".\nLLMs are effective at reasoning with both of these formats. There are also\nlots of JavaScript utilities for working with these formats."]}),"\n",(0,o.jsx)(n.h2,{id:"clean-up-text-as-you-ingest",children:"Clean up Text as You Ingest"}),"\n",(0,o.jsxs)(n.p,{children:["You may want to clean up text as you ingest it. We recommend that you do this\nduring the ",(0,o.jsx)(n.code,{children:"pages"})," command stage. The ",(0,o.jsx)(n.code,{children:"pages"})," command is the\nstage where you have access to the raw text from the data source."]}),"\n",(0,o.jsxs)(n.admonition,{type:"note",children:[(0,o.jsxs)(n.mdxAdmonitionTitle,{children:["Why You Shouldn't Clean up Text in the ",(0,o.jsx)(n.code,{children:"embed"})," Command Stage"]}),(0,o.jsxs)(n.p,{children:["You could technically clean up text during the ",(0,o.jsx)(n.code,{children:"embed"})," command stage,\nbut this would be something of an anti-pattern since the ",(0,o.jsx)(n.code,{children:"embed"})," command\nis supposed to be for chunking and creating embeddings, not manipulating the original content."]})]}),"\n",(0,o.jsxs)(n.p,{children:["To clean up text during the ",(0,o.jsx)(n.code,{children:"pages"})," stage, include the logic in your ",(0,o.jsx)(n.code,{children:"DataSource.fetchPages()"})," method.\nThe cleaned text will be persisted to the ",(0,o.jsx)(n.code,{children:"pages"})," collection, and used down stream by the ",(0,o.jsx)(n.code,{children:"embed"})," command."]}),"\n",(0,o.jsx)(n.p,{children:"Some content that you may want to clean up includes:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Remove HTML tags."}),"\n",(0,o.jsx)(n.li,{children:"Remove Markdown images and links."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"mongodb-rag-ingest"})," package comes with utilities for both of these.\nLearn more about them in the ",(0,o.jsx)(n.a,{href:"/chatbot/ingest/data-sources#data-source-helpers",children:"Data Sources"})," documentation."]}),"\n",(0,o.jsx)(n.h2,{id:"refine-the-chunking-strategy",children:"Refine the Chunking Strategy"}),"\n",(0,o.jsx)(n.p,{children:"In the context of building RAG apps, chunking refers to breaking down large pieces\nof text into smaller segments. It's important to optimize the content that\nyou get back from the vector database and then use with the large language model."}),"\n",(0,o.jsx)(n.p,{children:"We have provided reasonable defaults that should work for many RAG apps,\nbut you can customize the chunking strategy to be optimized for your application."}),"\n",(0,o.jsxs)(n.p,{children:["You can configure the ",(0,o.jsx)(n.a,{href:"/chatbot/ingest/configuration-reference#chunkoptions",children:(0,o.jsx)(n.code,{children:"ChunkOptions"})}),"\nin your configuration file to customize the chunking strategy."]}),"\n",(0,o.jsxs)(n.p,{children:["For example, you could change the ",(0,o.jsx)(n.code,{children:"maxChunkSize"})," to be smaller or larger\nor make the chunks overlap."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:"const chunkOptions: ChunkOptions = {\n  maxChunkSize: 1000,\n  overlap: 100,\n  // ...other properties\n};\n"})}),"\n",(0,o.jsx)(n.h2,{id:"add-metadata-to-chunks",children:"Add Metadata to Chunks"}),"\n",(0,o.jsx)(n.p,{children:"One of the most important things you can do to optimize your ingestion process\nis add metadata to the chunks sent to the embedding API."}),"\n",(0,o.jsx)(n.p,{children:"For example, you can add metadata for things like the title of the page that\nthe content came from and the name of the data source that the content came from."}),"\n",(0,o.jsxs)(n.p,{children:["To add metadata to chunks, you can use the ",(0,o.jsx)(n.code,{children:"ChunkOptions.transform()"})," function in the ",(0,o.jsx)(n.code,{children:"mongodb-rag-ingest"})," package. The ",(0,o.jsx)(n.code,{children:"mongodb-rag-ingest"})," package comes with the\n",(0,o.jsx)(n.code,{children:"standardChunkFrontMatterUpdater()"})," function which adds all the properties from the\n",(0,o.jsx)(n.code,{children:"Page.metadata"})," object and the ",(0,o.jsx)(n.code,{children:"Page.title"})," as ",(0,o.jsx)(n.a,{href:"https://jekyllrb.com/docs/front-matter/",children:"Front Matter"}),"\nto the chunk."]}),"\n",(0,o.jsxs)(n.p,{children:["Say you have this document in the ",(0,o.jsx)(n.code,{children:"pages"})," collection:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'{\n  title: "My Page",\n  body: "This is my page...",\n  metadata: {\n    tags: ["tag1", "tag2"],\n    productName: "Product Name",\n  },\n  // ...other properties\n}\n'})}),"\n",(0,o.jsxs)(n.p,{children:["When chunking the page, ",(0,o.jsx)(n.code,{children:"standardChunkFrontMatterUpdater()"})," transforms\nthe page text into the following chunk text:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"---\ntitle: My Page\ntags:\n  - tag1\n  - tag2\nproductName: Product Name\n---\nThis is my page...\n"})}),"\n",(0,o.jsx)(n.p,{children:"You then use this chunk with metadata to create the embedding.\nThe embedding then has the semantic meaning of both the chunk content and metadata."}),"\n",(0,o.jsxs)(n.p,{children:["Here's how you can add the ",(0,o.jsx)(n.code,{children:"standardChunkFrontMatterUpdater()"})," function to your configuration:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-ts",children:'import { standardChunkFrontMatterUpdater } from "mongodb-rag-ingest/embed";\nimport { ChunkOptions } from "mongodb-rag-ingest/embed";\n\nconst chunkOptions: ChunkOptions = {\n  transform: standardChunkFrontMatterUpdater,\n  // ...other properties\n};\n'})}),"\n",(0,o.jsxs)(n.p,{children:["For more information on how to configure ",(0,o.jsx)(n.code,{children:"ChunkOptions"}),",\nrefer to the ",(0,o.jsx)(n.a,{href:"/chatbot/ingest/configuration-reference#chunkoptions",children:"Configuration Reference"})," documentation."]})]})}function l(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>s});var o=t(67294);const a={},i=o.createContext(a);function s(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);