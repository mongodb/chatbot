"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7676],{10734:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>d});var t=r(85893),o=r(11151);const s={},a="Retrieval Augmented Generation (RAG)",i={id:"server/rag/index",title:"Retrieval Augmented Generation (RAG)",description:"You can use the MongoDB Chatbot Server to perform retrieval augmented generation (RAG).",source:"@site/docs/server/rag/index.md",sourceDirName:"server/rag",slug:"/server/rag/",permalink:"/chatbot/server/rag/",draft:!1,unlisted:!1,editUrl:"https://github.com/mongodb/chatbot/tree/main/docs/docs/server/rag/index.md",tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"Chat with an LLM",permalink:"/chatbot/server/llm"},next:{title:"Pre-Process User Queries",permalink:"/chatbot/server/rag/preprocess"}},c={},d=[{value:"What is RAG?",id:"what-is-rag",level:2},{value:"Generate User Message with RAG",id:"generate-user-message-with-rag",level:2},{value:"Configure RAG",id:"configure-rag",level:3},{value:"Data Flow",id:"data-flow",level:3}];function m(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",...(0,o.a)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"retrieval-augmented-generation-rag",children:"Retrieval Augmented Generation (RAG)"}),"\n",(0,t.jsx)(n.p,{children:"You can use the MongoDB Chatbot Server to perform retrieval augmented generation (RAG)."}),"\n",(0,t.jsx)(n.h2,{id:"what-is-rag",children:"What is RAG?"}),"\n",(0,t.jsx)(n.p,{children:"RAG is a technique that improves chatbot response quality by grounding answers\nin a knowledge base. Before a user query is sent to an LLM to generate a response,\nthe query is used to retrieve relevant information from a knowledge base.\nThe LLM responds to the user query based on the information from the knowledge base."}),"\n",(0,t.jsx)(n.p,{children:"By grounding the response in contextual information from the knowledge base,\nthe chatbot can generate more relevant and accurate responses."}),"\n",(0,t.jsxs)(n.p,{children:["To learn more about RAG, refer to the article ",(0,t.jsx)(n.a,{href:"https://www.mongodb.com/basics/retrieval-augmented-generation",children:"What is Retrieval-Augmented Generation (RAG)?"})," from MongoDB."]}),"\n",(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:" RAG Overview Diagram "}),(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"RAG Overview Diagram",src:r(40788).Z+"",width:"1728",height:"982"})})]}),"\n",(0,t.jsx)(n.h2,{id:"generate-user-message-with-rag",children:"Generate User Message with RAG"}),"\n",(0,t.jsxs)(n.p,{children:["You can perform RAG in the MongoDB Chatbot Server by implementing a ",(0,t.jsx)(n.a,{href:"/chatbot/reference/server/modules#generateuserpromptfunc",children:(0,t.jsx)(n.code,{children:"GenerateUserPromptFunc"})})," function."]}),"\n",(0,t.jsxs)(n.p,{children:["The MongoDB Chatbot Server comes with the ",(0,t.jsx)(n.a,{href:"/chatbot/reference/server/modules#makeraggenerateuserprompt",children:(0,t.jsx)(n.code,{children:"makeRagGenerateUserPrompt()"})})," function that you can use to perform RAG with Atlas Vector Search."]}),"\n",(0,t.jsx)(n.h3,{id:"configure-rag",children:"Configure RAG"}),"\n",(0,t.jsxs)(n.p,{children:["To configure the ",(0,t.jsx)(n.code,{children:"makeRagGenerateUserPrompt()"})," function, include it in the\n",(0,t.jsx)(n.a,{href:"/chatbot/reference/server/interfaces/ConversationsRouterParams#generateuserprompt",children:(0,t.jsx)(n.code,{children:"AppConfig.conversationsRoute.generateUserPrompt"})})," property."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'import {\n  makeMongoDbEmbeddedContentStore,\n  makeOpenAiEmbedder,\n  makeMongoDbConversationsService,\n  AppConfig,\n  makeDefaultFindContent,\n  GenerateUserPromptFunc,\n  makeRagGenerateUserPrompt,\n  MakeUserMessageFunc,\n} from "mongodb-chatbot-server";\nimport { stripIndents } from "common-tags";\nimport { makePreprocessMongoDbUserQuery } from "./processors/makePreprocessMongoDbUserQuery";\nimport { AzureOpenAI } from "mongodb-rag-core/openai";\n\n// Make preprocessor\nconst mongoDbUserQueryPreprocessor = makePreprocessMongoDbUserQuery({\n  azureOpenAiServiceConfig: {\n    apiKey: OPENAI_API_KEY,\n    baseUrl: OPENAI_ENDPOINT,\n    deployment: OPENAI_CHAT_COMPLETION_DEPLOYMENT,\n    version: OPENAI_CHAT_COMPLETION_MODEL_VERSION,\n  },\n  numRetries: 0,\n  retryDelayMs: 5000,\n});\n\nexport const embeddedContentStore = makeMongoDbEmbeddedContentStore({\n  connectionUri: MONGODB_CONNECTION_URI,\n  databaseName: MONGODB_DATABASE_NAME,\n  searchIndex: {\n    embeddingName: OPENAI_EMBEDDING_DEPLOYMENT,\n  }\n});\nexport const embedder = makeOpenAiEmbedder({\n  openAiClient,\n  deployment: OPENAI_EMBEDDING_DEPLOYMENT,\n  backoffOptions: {\n    numOfAttempts: 3,\n    maxDelay: 5000,\n  },\n});\nexport const findContent = makeDefaultFindContent({\n  embedder,\n  store: embeddedContentStore,\n  findNearestNeighborsOptions: {\n    k: 5,\n    path: "embedding",\n    indexName: VECTOR_SEARCH_INDEX_NAME,\n    minScore: 0.9,\n  },\n});\n\n// Make user message\nexport const makeUserMessage: MakeUserMessageFunc = async function ({\n  preprocessedUserMessage,\n  originalUserMessage,\n  content,\n  queryEmbedding,\n}) {\n  const chunkSeparator = "~~~~~~";\n  const context = content.map((c) => c.text).join(`\\n${chunkSeparator}\\n`);\n  const contentForLlm = `Using the following information, answer the question.\nDifferent pieces of information are separated by "${chunkSeparator}".\n\n<Information>\n${context}\n<End information>\n\n<Question>\n${preprocessedUserMessage ?? originalUserMessage}\n<End Question>`;\n  return {\n    role: "user",\n    content: originalUserMessage,\n    embedding: queryEmbedding,\n    preprocessedContent: preprocessedUserMessage,\n    contentForLlm,\n  };\n};\n\nexport const generateUserPrompt: GenerateUserPromptFunc =\n  makeRagGenerateUserPrompt({\n    queryPreprocessor: mongoDbUserQueryPreprocessor,\n    findContent,\n    makeReferenceLinks: makeMongoDbReferences,\n    makeUserMessage,\n  });\n\nexport const config: AppConfig = {\n  conversationsRouterConfig: {\n    generateUserPrompt,\n    // ...\n  },\n  // ...\n};\n'})}),"\n",(0,t.jsx)(n.h3,{id:"data-flow",children:"Data Flow"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"makeRagGenerateUserPromptFunc()"})," function has the following data flow:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["(Optional) Preprocess the user message. You can use this step to transform the\nuser message before it is used to retrieve relevant content with to Atlas Vector Search.\nTo learn more, refer to the ",(0,t.jsx)(n.a,{href:"/chatbot/server/rag/preprocess",children:"Pre-process User Queries"})," guide."]}),"\n",(0,t.jsxs)(n.li,{children:["Retrieve relevant content from Atlas Vector Search. To learn more, refer to the\n",(0,t.jsx)(n.a,{href:"/chatbot/server/rag/retrieve",children:"Retrieve Context Information"})," guide."]}),"\n",(0,t.jsx)(n.li,{children:"Removes any chunks that would exceed the max context tokens."}),"\n",(0,t.jsx)(n.li,{children:"Generate the user prompt and references based on the retrieved content."}),"\n",(0,t.jsx)(n.li,{children:"Return generated user prompt and references."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Also, you can reject the user message at any point in the flow.\nWhen the message is rejected, the server responds with a static response."}),"\n",(0,t.jsx)(n.mermaid,{value:"graph TD\n\n    USER[Receive User Message] --\x3e PRE[Optional: Pre-process User Queries]\n    PRE --\x3e RET[Retrieve Context Information & References]\n    RET --\x3e REM[Remove Chunks]\n    REM --\x3e GEN[Generate User Prompt]\n    REM --\x3e REF[Generate References]\n    GEN --\x3e GUM[Return Generated User Message & References]\n    REF --\x3e GUM\n    PRE --\x3e|Reject Message| REJ[Reject User Message]\n    RET --\x3e|No results| REJ\n    GEN --\x3e|Reject Message| REJ"})]})}function h(e={}){const{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},40788:(e,n,r)=>{r.d(n,{Z:()=>t});const t=r.p+"assets/images/rag-diagram-f0b0c05c585dff8804f5e1b087648780.webp"},11151:(e,n,r)=>{r.d(n,{Z:()=>i,a:()=>a});var t=r(67294);const o={},s=t.createContext(o);function a(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);