import { stripIndents } from "common-tags";
import { strict as assert } from "assert";
import {
  Request as ExpressRequest,
  Response as ExpressResponse,
} from "express";
import { DbMessage, Message, ToolMessage } from "mongodb-rag-core";
import { ObjectId } from "mongodb-rag-core/mongodb";
import {
  ConversationsService,
  Conversation,
  SomeMessage,
  makeDataStreamer,
} from "mongodb-rag-core";
import {
  ApiMessage,
  RequestError,
  convertMessageFromDbToApi,
  makeRequestError,
} from "./utils";
import { getRequestId, logRequest, sendErrorResponse } from "../../utils";
import { object, z } from "zod";
import { SomeExpressRequest } from "../../middleware/validateRequestSchema";
import {
  AddCustomDataFunc,
  ConversationsRouterLocals,
} from "./conversationsRouter";
import { wrapTraced, Logger } from "mongodb-rag-core/braintrust";
import { UpdateTraceFunc, updateTraceIfExists } from "./UpdateTraceFunc";
import {
  GenerateResponse,
  GenerateResponseParams,
} from "../../processors/GenerateResponse";

export const DEFAULT_MAX_INPUT_LENGTH = 3000; // magic number for max input size for LLM
export const DEFAULT_MAX_USER_MESSAGES_IN_CONVERSATION = 7; // magic number for max messages in a conversation

export type CreateResponseRequestBody = z.infer<
  typeof CreateResponseRequestBodySchema
>;

const MessageStatusSchema = z
  .enum(["in_progress", "completed", "incomplete"])
  .optional()
  .describe(
    "The status of the item. One of `in_progress`, `completed`, or `incomplete`. Populated when items are returned via API."
  );

export const CreateResponseRequestBodySchema = z.object({
  model: z.string(),
  input: z.union([
    z.string(),

    z.array(
      z.union([
        z.object({
          role: z.enum(["user", "assistant", "system"]),
          content: z.string(),
          type: z.literal("message").optional(),
        }),
        // function tool call
        z.object({
          arguments: z
            .string()
            .describe("JSON string of arguments passed to the function"),
          name: z.string().describe("Name of the function to run"),
          type: z.literal("function_call"),
          id: z.string().optional().describe("Unique ID of the function call"),
          status: MessageStatusSchema,
        }),
        // function tool call output
        z.object({
          call_id: z
            .string()
            .describe(
              "Unique ID of the function tool call generated by the model"
            ),
          output: z.string().describe("JSON string of the function tool call"),
          type: z.literal("function_call_output"),
          id: z
            .string()
            .optional()
            .describe(
              "The unique ID of the function tool call output. Populated when this item is returned via API."
            ),
          status: MessageStatusSchema,
        }),
      ])
    ),
  ]),
  max_output_tokens: z.number().max(4000).optional().default(1000),
  metadata: z
    .record(z.string(), z.string().max(512))
    .optional()
    .refine(
      (metadata) => Object.keys(metadata ?? {}).length <= 16,
      "Too many metadata fields. Max 16."
    ),
  previous_response_id: z
    .string()
    .optional()
    .describe(
      "The unique ID of the previous response to the model. Use this to create multi-turn conversations."
    ),
  store: z
    .boolean()
    .optional()
    .describe("Whether to store the response in the conversation.")
    .default(true),
  stream: z.literal(true, {
    errorMap: () => ({ message: "'stream' must be true" }),
  }),
  temperature: z
    .union([
      z.literal(0, {
        errorMap: () => ({ message: "Temperature must be 0 or unset" }),
      }),
      z.undefined(),
    ])
    .optional()
    .describe("Temperature for the model. Defaults to 0.")
    .default(0),
  tool_choice: z
    .union([
      z.enum(["none", "only", "auto"]),
      z
        .object({
          name: z.string(),
          type: z.literal("function"),
        })
        .describe("Function tool choice"),
    ])
    .optional()
    .describe("Tool choice for the model. Defaults to 'auto'.")
    .default("auto"),
  tools: z
    .array(
      z.object({
        name: z.string(),
        description: z.string().optional(),
        parameters: z
          .record(z.string(), z.unknown())
          .describe(
            "A JSON schema object describing the parameters of the function."
          ),
      })
    )
    .optional()
    .describe(
      "Tools for the model to use. Required if tool_choice is 'function'."
    ),

  user: z.string().optional().describe("The user ID of the user."),
});

export const CreateResponseRequest = SomeExpressRequest.merge(
  z.object({
    headers: z.object({
      "req-id": z.string(),
    }),
    body: CreateResponseRequestBodySchema,
  })
);

export type CreateResponseRequest = z.infer<typeof CreateResponseRequest>;

export interface CreateResponseRouteParams {
  conversations: ConversationsService;
  maxInputLengthCharacters?: number;
  maxUserMessagesInConversation?: number;
  generateResponse: GenerateResponse;
  addMessageToConversationCustomData?: AddCustomDataFunc;
  /**
    If present, the route will create a new conversation
    when given the `conversationIdPathParam` in the URL.
   */
  createConversation?: {
    /**
      Create a new conversation when the `conversationId` is the string "null".
     */
    createOnNullConversationId: boolean;
    /**
      The custom data to add to the new conversation
      when it is created.
     */
    addCustomData?: AddCustomDataFunc;
  };

  /**
    Custom function to update the Braintrust tracing
    after the response has been sent to the user.
    Can add additional tags, scores, etc.
   */
  updateTrace?: UpdateTraceFunc;
  braintrustLogger?: Logger<true>;
  supportedModels: string[];
}

export function makeCreateResponseRoute({
  conversations,
  generateResponse,
  maxInputLengthCharacters = DEFAULT_MAX_INPUT_LENGTH,
  maxUserMessagesInConversation = DEFAULT_MAX_USER_MESSAGES_IN_CONVERSATION,
  addMessageToConversationCustomData,
  supportedModels,
  updateTrace,
}: CreateResponseRouteParams) {
  return async (
    req: ExpressRequest<
      CreateResponseRequest["params"],
      unknown,
      CreateResponseRequest["body"]
    >,
    res: ExpressResponse<ApiMessage, ConversationsRouterLocals>
  ) => {
    const dataStreamer = makeDataStreamer();
    const reqId = getRequestId(req); // TODO: figure this one out...
    try {
      const {
        body: {
          input,
          model,
          metadata,
          previous_response_id,
          store,
          stream,
          temperature,
          tool_choice,
          tools,
          user,
          max_output_tokens,
        },
        ip,
      } = req;

      // --- MODEL CHECK ---
      if (!supportedModels.includes(model)) {
        throw makeRequestError({
          httpStatus: 400,
          message: `Model ${model} is not supported.`,
        });
      }

      // --- MAX INPUT LENGTH CHECK ---
      if (JSON.stringify(input).length > maxInputLengthCharacters) {
        throw makeRequestError({
          httpStatus: 400,
          message: "Message too long",
        });
      }

      const customData = await getCustomData({
        req,
        res,
        addMessageToConversationCustomData,
      });

      // --- LOAD CONVERSATION ---
      const conversation = await loadConversationByMessageId({
        messageId: previous_response_id,
        conversations,
      });

      // --- MAX CONVERSATION LENGTH CHECK ---
      const numUserMessages = conversation.messages.reduce(
        (acc, message) => (message.role === "user" ? acc + 1 : acc),
        0
      );
      if (numUserMessages >= maxUserMessagesInConversation) {
        // Omit the system prompt and assume the user always received one response per message
        throw makeRequestError({
          httpStatus: 400,
          message: `Too many messages. You cannot send more than ${maxUserMessagesInConversation} messages in this conversation.`,
        });
      }

      if (stream !== true) {
        throw makeRequestError({
          httpStatus: 400,
          message: "Stream must be true",
        });
      }

      if (stream) {
        dataStreamer.connect(res);
      }

      const assistantResponseMessageId = new ObjectId();

      // Only include the necessary message info for the conversastion.
      // This sends less data to Braintrust speeding up tracing
      // and also being more readable in the Braintrust UI.
      const traceConversation: Conversation = {
        ...conversation,
        messages: conversation.messages.map((message) => {
          const baseFields = {
            content: message.content,
            id: message.id,
            createdAt: message.createdAt,
            metadata: message.metadata,
          };

          if (message.role === "tool") {
            return {
              role: "tool",
              name: message.name,
              ...baseFields,
            } satisfies DbMessage<ToolMessage>;
          } else {
            return { ...baseFields, role: message.role } satisfies Exclude<
              Message,
              ToolMessage
            >;
          }
        }),
      };

      const { messages } = await generateResponseTraced({
        conversation: traceConversation,
        latestMessageText,
        clientContext,
        customData,
        dataStreamer,
        shouldStream,
        reqId,
        traceId: assistantResponseMessageId.toHexString(),
      });

      // --- SAVE QUESTION & RESPONSE ---
      const dbNewMessages = await addMessagesToDatabase({
        conversations,
        conversation,
        messages,
        assistantResponseMessageId,
      });
      const dbAssistantMessage = dbNewMessages[dbNewMessages.length - 1];

      assert(dbAssistantMessage !== undefined, "No assistant message found");
      const apiRes = convertMessageFromDbToApi(
        dbAssistantMessage,
        conversation._id
      );

      if (!shouldStream) {
        return res.status(200).json(apiRes);
      } else {
        dataStreamer.streamData({
          type: "metadata",
          data: { conversationId: conversation._id.toString() },
        });
        dataStreamer.streamData({
          type: "finished",
          data: apiRes.id,
        });
        if (dataStreamer.connected) {
          dataStreamer.disconnect();
        }

        await updateTraceIfExists({
          updateTrace,
          reqId,
          conversations,
          conversationId: conversation._id,
          assistantResponseMessageId: dbAssistantMessage.id,
        });
      }
    } catch (error) {
      const { httpStatus, message } =
        (error as Error).name === "RequestError"
          ? (error as RequestError)
          : makeRequestError({
              message: (error as Error).message,
              stack: (error as Error).stack,
              httpStatus: 500,
            });

      sendErrorResponse({
        res,
        reqId,
        httpStatus,
        errorMessage: message,
      });
    } finally {
      if (dataStreamer.connected) {
        dataStreamer.disconnect();
      }
    }
  };
}

// --- HELPERS ---

async function getCustomData({
  req,
  res,
  addMessageToConversationCustomData,
}: {
  req: ExpressRequest;
  res: ExpressResponse<ApiMessage, ConversationsRouterLocals>;
  addMessageToConversationCustomData?: AddCustomDataFunc;
}) {
  try {
    return addMessageToConversationCustomData
      ? await addMessageToConversationCustomData(req, res)
      : undefined;
  } catch (_err) {
    throw makeRequestError({
      httpStatus: 500,
      message: "Unable to process custom data",
    });
  }
}

interface AddMessagesToDatabaseParams {
  conversation: Conversation;
  conversations: ConversationsService;
  messages: SomeMessage[];
  assistantResponseMessageId: ObjectId;
}

async function addMessagesToDatabase({
  conversation,
  conversations,
  messages,
  assistantResponseMessageId,
}: AddMessagesToDatabaseParams) {
  (
    messages as Parameters<
      typeof conversations.addManyConversationMessages
    >[0]["messages"]
  )[messages.length - 1].id = assistantResponseMessageId;

  const conversationId = conversation._id;
  const dbMessages = await conversations.addManyConversationMessages({
    conversationId,
    messages,
  });
  return dbMessages;
}

async function loadConversationByMessageId({
  messageId,
  conversations,
  customData,
}: {
  messageId?: string;
  conversations: ConversationsService;
  customData?: Record<string, unknown>;
}): Promise<Conversation> {
  if (!messageId) {
    return await conversations.create({
      customData,
    });
  }
  const conversation = await conversations.findByMessageId({
    messageId: ObjectId.createFromHexString(messageId),
  });
  if (!conversation) {
    throw makeRequestError({
      httpStatus: 404,
      message: `Message ${messageId} not found`,
    });
  }
  return conversation;
}
