import { z } from "zod";
import type {
  Request as ExpressRequest,
  Response as ExpressResponse,
} from "express";
import { ObjectId } from "mongodb";
import type { APIError } from "mongodb-rag-core/openai";
import type {
  ConversationsService,
  Conversation,
  SomeMessage,
} from "mongodb-rag-core";
import { SomeExpressRequest } from "../../middleware";
import { getRequestId } from "../../utils";
import type { GenerateResponse } from "../../processors";
import {
  makeBadRequestError,
  makeInternalServerError,
  generateZodErrorMessage,
  sendErrorResponse,
  ERROR_TYPE,
} from "./errors";

export const ERR_MSG = {
  INPUT_STRING: "Input must be a non-empty string",
  INPUT_ARRAY:
    "Input must be a string or array of messages. See https://platform.openai.com/docs/api-reference/responses/create#responses-create-input for more information.",
  CONVERSATION_USER_ID_CHANGED:
    "Path: body.user - User ID has changed since the conversation was created.",
  METADATA_LENGTH: "Too many metadata fields. Max 16.",
  TEMPERATURE: "Temperature must be 0 or unset",
  STREAM: "'stream' must be true",
  INVALID_OBJECT_ID: (id: string) =>
    `Path: body.previous_response_id - ${id} is not a valid ObjectId`,
  MESSAGE_NOT_FOUND: (messageId: string) =>
    `Path: body.previous_response_id - Message ${messageId} not found`,
  MESSAGE_NOT_LATEST: (messageId: string) =>
    `Path: body.previous_response_id - Message ${messageId} is not the latest message in the conversation`,
  TOO_MANY_MESSAGES: (max: number) =>
    `Too many messages. You cannot send more than ${max} messages in this conversation.`,
  MODEL_NOT_SUPPORTED: (model: string) =>
    `Path: body.model - ${model} is not supported.`,
  MAX_OUTPUT_TOKENS: (input: number, max: number) =>
    `Path: body.max_output_tokens - ${input} is greater than the maximum allowed ${max}.`,
};

const CreateResponseRequestBodySchema = z.object({
  model: z.string(),
  instructions: z.string().optional(),
  input: z.union([
    z.string().refine((input) => input.length > 0, ERR_MSG.INPUT_STRING),
    z
      .array(
        z.union([
          z.object({
            type: z.literal("message").optional(),
            role: z.enum(["user", "assistant", "system"]),
            content: z.string(),
          }),
          // function tool call
          z.object({
            type: z.literal("function_call"),
            id: z
              .string()
              .optional()
              .describe("Unique ID of the function tool call"),
            name: z.string().describe("Name of the function tool to call"),
            arguments: z
              .string()
              .describe(
                "JSON string of arguments passed to the function tool call"
              ),
            status: z.enum(["in_progress", "completed", "incomplete"]),
          }),
          // function tool call output
          z.object({
            type: z.literal("function_call_output"),
            id: z
              .string()
              .optional()
              .describe("The unique ID of the function tool call output"),
            call_id: z
              .string()
              .describe(
                "Unique ID of the function tool call generated by the model"
              ),
            output: z
              .string()
              .describe("JSON string of the function tool call"),
            status: z.enum(["in_progress", "completed", "incomplete"]),
          }),
        ])
      )
      .refine((input) => input.length > 0, ERR_MSG.INPUT_ARRAY),
  ]),
  max_output_tokens: z.number().min(0).default(1000),
  metadata: z
    .record(z.string(), z.string().max(512))
    .optional()
    .refine(
      (metadata) => Object.keys(metadata ?? {}).length <= 16,
      ERR_MSG.METADATA_LENGTH
    ),
  previous_response_id: z
    .string()
    .optional()
    .describe("The unique ID of the previous response to the model."),
  store: z
    .boolean()
    .optional()
    .describe("Whether to store the response in the conversation.")
    .default(true),
  stream: z.boolean().refine((stream) => stream, ERR_MSG.STREAM),
  temperature: z
    .number()
    .refine((temperature) => temperature === 0, ERR_MSG.TEMPERATURE)
    .optional()
    .describe("Temperature for the model. Defaults to 0.")
    .default(0),
  tool_choice: z
    .union([
      z.enum(["none", "only", "auto"]),
      z
        .object({
          name: z.string(),
          type: z.literal("function"),
        })
        .describe("Function tool choice"),
    ])
    .optional()
    .describe("Tool choice for the model. Defaults to 'auto'.")
    .default("auto"),
  tools: z
    .array(
      z.object({
        name: z.string(),
        description: z.string().optional(),
        parameters: z
          .record(z.string(), z.unknown())
          .describe(
            "A JSON schema object describing the parameters of the function."
          ),
      })
    )
    .optional()
    .describe("Tools for the model to use."),

  user: z.string().optional().describe("The user ID of the user."),
});

const CreateResponseRequestSchema = SomeExpressRequest.merge(
  z.object({
    headers: z.object({
      "req-id": z.string(),
    }),
    body: CreateResponseRequestBodySchema,
  })
);

export type CreateResponseRequest = z.infer<typeof CreateResponseRequestSchema>;

export interface CreateResponseRouteParams {
  conversations: ConversationsService;
  generateResponse: GenerateResponse;
  supportedModels: string[];
  maxOutputTokens: number;
  maxUserMessagesInConversation: number;
}

export function makeCreateResponseRoute({
  conversations,
  generateResponse,
  supportedModels,
  maxOutputTokens,
  maxUserMessagesInConversation,
}: CreateResponseRouteParams) {
  return async (
    req: ExpressRequest,
    res: ExpressResponse<{ status: string }, any> // TODO: fix type
  ) => {
    const reqId = getRequestId(req);
    const headers = req.headers as Record<string, string>;

    try {
      // --- INPUT VALIDATION ---
      const { error, data } = await CreateResponseRequestSchema.safeParseAsync(
        req
      );
      if (error) {
        throw makeBadRequestError({
          error: new Error(generateZodErrorMessage(error)),
          headers,
        });
      }

      const {
        body: {
          model,
          max_output_tokens,
          previous_response_id,
          store,
          metadata,
          user,
          input,
        },
      } = data;

      // --- MODEL CHECK ---
      if (!supportedModels.includes(model)) {
        throw makeBadRequestError({
          error: new Error(ERR_MSG.MODEL_NOT_SUPPORTED(model)),
          headers,
        });
      }

      // --- MAX OUTPUT TOKENS CHECK ---
      if (max_output_tokens > maxOutputTokens) {
        throw makeBadRequestError({
          error: new Error(
            ERR_MSG.MAX_OUTPUT_TOKENS(max_output_tokens, maxOutputTokens)
          ),
          headers,
        });
      }

      // --- LOAD CONVERSATION ---
      const conversation = await loadConversationByMessageId({
        messageId: previous_response_id,
        conversations,
        headers,
        metadata,
        userId: user,
      });

      // --- CONVERSATION USER ID CHECK ---
      if (hasConversationUserIdChanged(conversation, user)) {
        throw makeBadRequestError({
          error: new Error(ERR_MSG.CONVERSATION_USER_ID_CHANGED),
          headers,
        });
      }

      // --- MAX CONVERSATION LENGTH CHECK ---
      if (
        hasTooManyUserMessagesInConversation(
          conversation,
          maxUserMessagesInConversation
        )
      ) {
        throw makeBadRequestError({
          error: new Error(
            ERR_MSG.TOO_MANY_MESSAGES(maxUserMessagesInConversation)
          ),
          headers,
        });
      }

      // TODO: actually implement this call
      const { messages } = await generateResponse({} as any);

      // --- STORE MESSAGES IN CONVERSATION ---
      if (store) {
        await saveMessagesToConversation({
          conversations,
          conversation,
          metadata,
          input,
          messages,
        });
      }

      return res.status(200).send({ status: "ok" });
    } catch (error) {
      const standardError =
        (error as APIError)?.type === ERROR_TYPE
          ? (error as APIError)
          : makeInternalServerError({ error: error as Error, headers });

      sendErrorResponse({
        res,
        reqId,
        error: standardError,
      });
    }
  };
}

interface LoadConversationByMessageIdParams {
  messageId?: string;
  conversations: ConversationsService;
  headers: Record<string, string>;
  metadata?: Record<string, string>;
  userId?: string;
}

const loadConversationByMessageId = async ({
  messageId,
  conversations,
  headers,
  metadata,
  userId,
}: LoadConversationByMessageIdParams): Promise<Conversation> => {
  if (!messageId) {
    return await conversations.create({
      customData: { metadata, userId },
    });
  }

  const conversation = await conversations.findByMessageId({
    messageId: convertToObjectId(messageId, headers),
  });

  if (!conversation) {
    throw makeBadRequestError({
      error: new Error(ERR_MSG.MESSAGE_NOT_FOUND(messageId)),
      headers,
    });
  }

  const latestMessage = conversation.messages[conversation.messages.length - 1];
  if (latestMessage.id.toString() !== messageId) {
    throw makeBadRequestError({
      error: new Error(ERR_MSG.MESSAGE_NOT_LATEST(messageId)),
      headers,
    });
  }

  return conversation;
};

const convertToObjectId = (
  inputString: string,
  headers: Record<string, string>
): ObjectId => {
  try {
    return new ObjectId(inputString);
  } catch (error) {
    throw makeBadRequestError({
      error: new Error(ERR_MSG.INVALID_OBJECT_ID(inputString)),
      headers,
    });
  }
};

// ideally this doesn't need to be exported once nothing else relies on it (addMessageToConversation for now)
export const hasTooManyUserMessagesInConversation = (
  conversation: Conversation,
  maxUserMessagesInConversation: number
): boolean => {
  const numUserMessages = conversation.messages.reduce(
    (acc, message) => (message.role === "user" ? acc + 1 : acc),
    0
  );
  return numUserMessages >= maxUserMessagesInConversation;
};

const hasConversationUserIdChanged = (
  conversation: Conversation,
  userId?: string
): boolean => {
  return conversation.customData?.userId !== userId;
};

interface AddMessagesToConversationParams {
  conversations: ConversationsService;
  conversation: Conversation;
  metadata?: Record<string, string>;
  input: CreateResponseRequest["body"]["input"];
  messages: Array<SomeMessage>;
}

const saveMessagesToConversation = async ({
  conversations,
  conversation,
  metadata,
  input,
  messages,
}: AddMessagesToConversationParams) => {
  const finalMessages: Array<SomeMessage> = [];

  if (typeof input === "string") {
    finalMessages.push({
      role: "user",
      content: input,
      metadata,
    });
  } else {
    finalMessages.push(
      // TODO: fix type here, but the gist is to filter out any function/tool calls
      ...input.filter((message) => message.type === "message")
    );
  }

  finalMessages.push(
    ...messages.map((message) => ({
      ...message,
      metadata,
    }))
  );

  await conversations.addManyConversationMessages({
    conversationId: conversation._id,
    messages: finalMessages,
  });
};
